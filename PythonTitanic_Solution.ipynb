{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-september",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-equilibrium",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().sum(axis = 1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'] = df['Cabin'].fillna('Z0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Cabin', 'Cabin_number']] = df['Cabin'].str.extract('([A-Z]*)([0-9]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin_number'] = df['Cabin_number'].apply(lambda x: 0 if x=='' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().sum(axis = 1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data = pd.get_dummies(df[['Sex','Cabin', 'Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-margin",
   "metadata": {},
   "source": [
    "## Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(df):\n",
    "    one_hot_data = pd.get_dummies(df[['Cabin', 'Embarked']])\n",
    "    df_hot = df[['Survived','Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin_number']].join(one_hot_data)\n",
    "    return df_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot = get_one_hot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-spirit",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df_hot, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-supplier",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, max_depth=4, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train.iloc[:, 1:], train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-geneva",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(model, df):\n",
    "    plot_confusion_matrix(model, df.iloc[:, 1:], df['Survived'].values)\n",
    "    M = confusion_matrix(df['Survived'].values, model.predict(df.iloc[:, 1:]))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = confusion(model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-popularity",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = M[1,1] / M[:, 1].sum()\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = M[1, 1] / M[1, :].sum()\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = 2 * (precision*recall)/ (precision + recall)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(model, df):\n",
    "    return f1_score(df['Survived'].values, model.predict(df.iloc[:, 1:]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = get_f1(model, test)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.argmax([get_f1(estimator, test) for estimator in model.estimators_])\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = confusion(model.estimators_[n], test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_f1(model.estimators_[n], test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-drill",
   "metadata": {},
   "source": [
    "## Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(model.estimators_[n], test.iloc[:, 1:], test['Survived'], n_repeats=10,\n",
    "                                random_state=7)\n",
    "perm_sorted_idx = result.importances_mean.argsort()\n",
    "tree_importance_sorted_idx = np.argsort(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(result.importances[perm_sorted_idx][-10:].T, vert=False, labels=test.iloc[:, 1:].columns[perm_sorted_idx][-10:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-scheduling",
   "metadata": {},
   "source": [
    "## Plot tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "plt.figure(figsize=(20, 20))\n",
    "tree.plot_tree(model.estimators_[n],\n",
    "               feature_names = train.iloc[:, 1:].columns, \n",
    "               class_names=['no', 'yes'],\n",
    "               filled = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv')\n",
    "test.to_csv('test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
